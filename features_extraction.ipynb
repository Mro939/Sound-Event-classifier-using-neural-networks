{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio analysis\n",
    "import librosa\n",
    "\n",
    "# Others\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extraction(audio_file, hop_length):\n",
    "    \n",
    "    X, sample_rate = librosa.load(audio_file)    \n",
    "    mfccs = np.array(librosa.feature.mfcc(y=X, sr=sample_rate, hop_length=hop_length, n_mfcc=20).T)\n",
    "    chroma = np.array(librosa.feature.chroma_stft(y=X, sr=sample_rate, hop_length=hop_length).T)\n",
    "    #contrast = np.array(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T)\n",
    "    #tonnetz = np.array(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T)\n",
    "    extracted_features = np.hstack([mfccs, chroma])\n",
    "\n",
    "    return extracted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_file_analizer(path, saving_path, hop_length):\n",
    "    \n",
    "    DIM = 32\n",
    "    final_features = np.empty([0, DIM]) \n",
    "    labels = []\n",
    "    activities = ['alarm', 'baby', 'crash', 'dog', 'engine', 'femaleScream', 'femaleSpeech', 'fire', 'footsteps', 'general', 'knock', 'maleScream', 'maleSpeech', 'phone', 'piano']\n",
    "    file_ext = '*.wav' \n",
    "    \n",
    "    for activity in activities:\n",
    "        features = np.empty([0,DIM])\n",
    "        \n",
    "        for file in glob.glob(os.path.join(path, activity, file_ext)):\n",
    "            extracted_features = features_extraction(file, hop_length)\n",
    "            features = np.vstack([features, extracted_features]) \n",
    "            \n",
    "        for i in range (np.shape(features)[0]):\n",
    "            labels.append(activity)\n",
    "        \n",
    "        final_features=np.row_stack([final_features, features])\n",
    "     \n",
    "    now = datetime.now()\n",
    "    format = now.strftime('%d-%m-%Y, Hora: %H, Min: %M')\n",
    "\n",
    "    print('Features array shape: ', final_features.shape)\n",
    "    print('Labels array shape: ', np.shape(labels))\n",
    "    \n",
    "    # Saving features and labels as numpy arrays.\n",
    "    np.save(saving_path + 'features.npy', final_features)\n",
    "    np.save(saving_path + 'labels.npy', labels)\n",
    "    \n",
    "    # Uncomment the following lines for adding a date format when saving features and labels.\n",
    "    # np.save('/Users/Miguel.R/Desktop//Sound Class verano/features_'+format+'.npy', final_features)\n",
    "    # np.save('/Users/Miguel.R/Desktop//Sound Class verano/labels_'+format+'.npy', final_labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features array shape:  (722399, 32)\n",
      "Labels array shape:  (722399,)\n"
     ]
    }
   ],
   "source": [
    "# Features extraction:\n",
    "\n",
    "data_path = '/Users/miguel.r/Desktop/CITSEM/Sound Event Class - DCASE/DCASE Data'\n",
    "saving_path = '/Users/miguel.r/Desktop/CITSEM/Sound Event Class - DCASE/SCRIPTS Github/'\n",
    "audio_file_analizer(data_path, saving_path, 512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
